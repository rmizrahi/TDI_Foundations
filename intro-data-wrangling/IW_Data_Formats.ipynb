{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import expectexception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Python Data Formats\n",
    "\n",
    "Data is often stored in files.\n",
    "\n",
    "Your data can be encoded into one or more files and saved to disk. Ideally, this data is saved to disk in a way that can be later retrieved, identical to the data we started with.\n",
    "\n",
    "The simplest file example is saving arbitrary string data to a text file. That can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('example.txt', 'w') as f:\n",
    "    f.write('hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This creates a new file in the current directory called `example.txt`. Take this opportunity to use Jupyter's Terminal feature to verify the existence of this file.\n",
    "\n",
    "We can also verify the file using Jupyter's ability to execute OS system commands with the `!` character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 vagrant vagrant 11 Aug 11 00:32 example.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "11 bytes, just as expected.\n",
    "\n",
    "The contents of the file can be retrieved by opening the same file and reading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "with open('example.txt', 'r') as f:\n",
    "    print f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Reading and writing data files are just more sophisticated versions of our simple example above. A table of data could be written to a csv file by joining each row of data with commas and writing that line to a file. Of course nobody writes Python code to write data to a csv file like that because all of the data packages we will use provide utilities for writing data to csv and many other formats. Nevertheless, it is worth realizing that writing a csv file boils down to writing comma separated lists to a file for easy retrieval later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# don't write csv files like this...\n",
    "with open('csv_example.txt', 'w') as f:\n",
    "    f.write('column1,column2,column3\\n')\n",
    "    f.write('1,2,3\\n')\n",
    "    f.write('4,5,6\\n')\n",
    "    f.write('7,8,9\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Use Linux `cat` command to see the contents of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column1,column2,column3\r\n",
      "1,2,3\r\n",
      "4,5,6\r\n",
      "7,8,9\r\n"
     ]
    }
   ],
   "source": [
    "!cat csv_example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If we had a Pandas `DataFrame` we could more simply write the data to a csv file using the `to_csv` method. We'll cover that extensively later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## File Reading and Writing in more detail\n",
    "\n",
    "Before continuing, let's understand a little bit more about reading and writing files.\n",
    "\n",
    "The three steps for writing to a file are:\n",
    "\n",
    "* Open a file for writing with the `open` command, returning a file handle\n",
    "* Write to the file handle\n",
    "* Close the file handle\n",
    "\n",
    "The last step is necessary and can become a source of errors. Python has the convenient `with` keyword that ensures that the open file handle is always closed after the block of code is executed. Other programming languages don't always have this feature.\n",
    "\n",
    "If we were to code our example without the `with` keyword, it would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = open('example.txt', 'w')\n",
    "f.write('hello world')\n",
    "f.close()  # don't forget!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If we forgot to close the file, the file handle `f` would still be open. There is a limit to the number of open file handles your computer can handle; typically this is in the hundreds of thousands, if not more. That limit isn't usually the problem though: a more likely scenario is that an exception (error) is thrown after the file is opened and before the file is closed. If this happens, the `close` method is never called and the file stays open. This can cause problems for you later, particularly if you are using Windows. The Windows OS puts a lock on an opened file that prevents other processes from opening and writing to the same file; a residual lock can later cause a Python process to fail.\n",
    "\n",
    "Also, note that Python and your operating system may be somewhat *lazy* in that it won't always write the contents of your file to disk right away. Try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = open('mystery.txt', 'w')\n",
    "f.write('when will this text appear in the file?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Examine the current contents of `mystery.txt` with the `cat` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!cat mystery.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Egad!! The file is empty!\n",
    "\n",
    "If we had just attempted to save precious research results, we would be very upset right now.\n",
    "\n",
    "The issue is that the contents of `mystery.txt` are currently stored in a buffer somewhere, waiting for a convenient time to write it to disk. Usually Python will write it to disk for real when the buffer of pending writes gets to be a certain size. If we are impatient, we can use the `flush()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The `flush()` method empties the file buffer and pushes the content to disk. The `close()` method does the same thing but `flush()` keeps the file open and allows subsequent writes.\n",
    "\n",
    "Our file now contains the expected text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when will this text appear in the file?"
     ]
    }
   ],
   "source": [
    "!cat mystery.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This makes us happy, but let's not allow our exuberance to cause us to forget to close the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the future, prefer to read and write files using the `with` command as above. This won't always work for all situations. For example, you might be monitoring financial price data on a website, with the goal of writing data to a file continuously during market hours. In that situation you should keep the file open and flush after file writes. This will prevent data loss should your program crash at the end of the day.\n",
    "\n",
    "## Reading and Writing, or more precisely, Reading OR Writing, but not Both\n",
    "\n",
    "Observe that when we opened the files in our examples, we instructed the open command that we were opening the file for reading OR for writing. We must decide in advance how we will access the file. If we open a file for reading and attempt to write to it, we will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-15-5df4ba8f91c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fail.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'this will fail'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'fail.txt'\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception IOError\n",
    "\n",
    "with open('fail.txt', 'r') as f:\n",
    "    f.write('this will fail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Conveniently we opened the file with the `with` keyword so the file was closed for us, despite the error.\n",
    "\n",
    "The `'r'` mode argument in the open command indicates we wish to read from an existing file. If the file did not exist, we would get an error. If we used a `'w'` mode argument, we would write to the file. If the file already existed, we would overwrite the file. If we want to append to the file instead, use the mode `'a'`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('example.txt', 'a') as f:\n",
    "    f.write('\\nhello again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\r\n",
      "hello again"
     ]
    }
   ],
   "source": [
    "!cat example.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also open files for reading and writing in binary mode using a `'b'`, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('binary_example.txt', 'wb') as f:\n",
    "    f.write('hello world as binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world as binary"
     ]
    }
   ],
   "source": [
    "!cat binary_example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The result looks like ordinary text but this feature will be more important later when we write Python pickle files.\n",
    "\n",
    "There are some other file modes like 'r+' and 'w+' that allow for reading AND writing at the same time, but that requires more complex code to manage the file. For our purposes it is a better practice to either read OR write to a file, not both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## GZip Files\n",
    "\n",
    "GZip files are compressed files that reduce the size or footprint of files on disk.\n",
    "\n",
    "Random bytes of data are difficult or impossible to compress. A text file of English text is easy to compress because the letters in the English alphabet correspond to a limited, non-random set of bytes that can be encoded in a way that uses less space.\n",
    "\n",
    "As Data Scientists, this can be useful when working with large data files.\n",
    "\n",
    "Consider a situation where you must read data files from a network server across a slow network or from a slow hard drive. Of course it is always better and faster to read from fast local storage, but you might not always have that option, particularly for larger datasets. In these situations, the size of the files and your ability to read them may be a bottleneck limiting the speed of your overall data analysis. A compressed file will require your computer's CPU to uncompress the file contents, but that extra cost will often be smaller than the cost of reading a larger file over a network.\n",
    "\n",
    "Empirical testing of your data access can help determine if compressed zip files can speed up your analysis.\n",
    "\n",
    "Python has several libraries for reading and writing compressed files. One of these libraries is the `gzip` library. It can read and write files in the same format that the Linux `gzip` and `gunzip` commands use. Reading and writing files parallels reading and writing ordinary text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "sample_text = 'Python is awesome!'\n",
    "\n",
    "with gzip.open('test_gzip.txt.gz', 'wb') as f:\n",
    "    f.write(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note the use of file open mode 'wb', not 'w'. The extra 'b' is for binary.\n",
    "\n",
    "If we like we can look at the contents of our file `test_gzip.txt.gz` with the Linux `cat` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001f�\b\b\u001c",
      "��Y\u0002�test_gzip.txt\u0000\u000b",
      "�,���S�,VH,O-��MU\u0004\u0000���V\u0012\u0000\u0000\u0000"
     ]
    }
   ],
   "source": [
    "!cat test_gzip.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That's ugly!\n",
    "\n",
    "A better choice is the Linux command `zcat`, which is the same as `cat` but for gzipped files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is awesome!"
     ]
    }
   ],
   "source": [
    "!zcat test_gzip.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Our compressed file has been written, but the astute reader will notice that the compressed file we just wrote is larger than the text string we wrote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 vagrant vagrant 52 Aug 11 00:32 test_gzip.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l test_gzip.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "52 bytes, compared to 18 bytes in our `sample_text` string.\n",
    "\n",
    "This is because a gzip file has some space overhead from being a zip file. We need a much larger amount of data to see a difference. We'll get to that in a moment, but first, let's read the file back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is awesome!\n"
     ]
    }
   ],
   "source": [
    "with gzip.open('test_gzip.txt.gz', 'rb') as f:\n",
    "    print f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Truly, it is.\n",
    "\n",
    "Now let's create a much larger file to demonstrate the size differences between zipped and unzipped files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zikqxcldswcytbzdgxbg\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "random_text = ''.join(np.random.choice(list(string.lowercase), size=100000))\n",
    "\n",
    "print random_text[:20]\n",
    "\n",
    "with open('random_text.txt', 'w') as f:\n",
    "    f.write(random_text)\n",
    "\n",
    "with gzip.open('random_text.txt.gz', 'wb') as f:\n",
    "    f.write(random_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 vagrant vagrant 98K Aug 11 00:32 random_text.txt\r\n",
      "-rw-rw-r-- 1 vagrant vagrant 62K Aug 11 00:32 random_text.txt.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh random_text*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The zipped file has a compression ratio of 98 / 62 = ~ 1.6.\n",
    "\n",
    "The random text frustrates compression because of the lack of repeated patterns, but the limited character set (only lower case letters) offers room for compression.\n",
    "\n",
    "Real text or real data can often get a better compression ratio than 1.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pickle Files\n",
    "\n",
    "Pickle files are special Python files for serializing and de-serializing Python objects. The `pickle` module takes everything the Python interpreter knows about an object in memory and writes that to a binary file. It can later retrieve that information to put the object back in memory again, just as it was before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pickle file example code\n",
    "import pickle\n",
    "\n",
    "sample_data = [sample_text, 42, 3.1415926535, [1, 2, 3], {1: 'a', 2: 'b', 3: 'c'}]\n",
    "\n",
    "with open('sample_text.p', 'wb') as f:\n",
    "    pickle.dump(sample_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The written file is 112 bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 vagrant vagrant 112 Aug 11 00:32 sample_text.p\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l sample_text.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The file contents looks like it kind of makes sense...sort of?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(lp0\r\n",
      "S'Python is awesome!'\r\n",
      "p1\r\n",
      "aI42\r\n",
      "aF3.1415926535\r\n",
      "a(lp2\r\n",
      "I1\r\n",
      "aI2\r\n",
      "aI3\r\n",
      "aa(dp3\r\n",
      "I1\r\n",
      "S'a'\r\n",
      "p4\r\n",
      "sI2\r\n",
      "S'b'\r\n",
      "p5\r\n",
      "sI3\r\n",
      "S'c'\r\n",
      "p6\r\n",
      "sa."
     ]
    }
   ],
   "source": [
    "!cat sample_text.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This can be retrieved using the pickle `load` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python is awesome!', 42, 3.1415926535, [1, 2, 3], {1: 'a', 2: 'b', 3: 'c'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('sample_text.p', 'rb') as f:\n",
    "    retrieved_sample_data = pickle.load(f)\n",
    "\n",
    "retrieved_sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That's great! Same as before.\n",
    "\n",
    "Python pickle files are very versatile and can save arbitrary objects, including user defined classes. There are a few some limitations in what it can save though. It can't save open file handles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-31-cafa40db43cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, file, protocol)\u001b[0m\n",
      "\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1375\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m-> 1376\u001b[0;31m     \u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m   1378\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROTO\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[1;32m    304\u001b[0m             \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce_ex__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    308\u001b[0m                 \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__reduce__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/copy_reg.pyc\u001b[0m in \u001b[0;36m_reduce_ex\u001b[0;34m(self, proto)\u001b[0m\n",
      "\u001b[1;32m     68\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"can't pickle %s objects\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     72\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: can't pickle file objects\n"
     ]
    }
   ],
   "source": [
    "%%expect_exception TypeError\n",
    "\n",
    "test_file_handle = open('test_file_handle.txt', 'w')\n",
    "\n",
    "with open('error.p', 'wb') as f:\n",
    "    pickle.dump(test_file_handle, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This might seem like a unimportant limitation, but it can become a problem when you are using custom Python classes while logging data to a file. Don't worry about this for now though.\n",
    "\n",
    "Before we move on, let's be disciplined Python coders and close `test_file_handle`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_file_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The last thing to mention is that Python 2 (usually) comes with not one but two pickle libraries. The second one, `cPickle`, reads and writes faster than the other, but on some installations is not available. Therefore, some Python code you will see in the wild will import pickle like below to use the faster version when it is available but fall back to the standard one when it is not.\n",
    "\n",
    "The `cPickle` library is faster but if you not reading and writing a lot of pickle files, don't worry about this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## JSON Files\n",
    "\n",
    "[JSON](https://en.wikipedia.org/wiki/JSON) (JavaScript Object Notation) files are serialized text files that store data in key-value pairs. \n",
    "\n",
    "A Data Scientist will find this data format useful for writing unstructured data. Websites frequently use this format to communicate to and from your browser. You can easily scrape data from a website if you can consume these communications from the web server.\n",
    "\n",
    "Consider this example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "student1 = {'name': 'Gary',\n",
    "            'employment': ('librarian', 'research assistant'),\n",
    "            'age': 22,\n",
    "            'major': 'computer science',\n",
    "            'hobbies': ['running', 'climbing trees', 'eating ice cream'],\n",
    "            'grades': {'english': 82,\n",
    "                       'linear algebra': 97,\n",
    "                       'cpu design': 94}}\n",
    "\n",
    "student2 = {'name': 'Jill',\n",
    "            'age': 23,\n",
    "            'major': 'electrical engineering',\n",
    "            'minor': 'management',\n",
    "            'hobbies': ['swimming', 'reading', 'drawing', 'public speaking'],\n",
    "            'grades': {'french': 88,\n",
    "                       'calculus': 94,\n",
    "                       'electronics': 99,\n",
    "                       'control systems': 95}}\n",
    "\n",
    "student_list = [student1, student2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You'll note that `student1` and `student2` are both dictionaries that contain nested dictionaries and lists. Neither could easily fit into an ordinary structured table because they have a variable number of grades and hobbies. They could be shoehorned in (and tragically we've seen this happen) but not without complications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'age': 22,\n",
       "  'employment': ('librarian', 'research assistant'),\n",
       "  'grades': {'cpu design': 94, 'english': 82, 'linear algebra': 97},\n",
       "  'hobbies': ['running', 'climbing trees', 'eating ice cream'],\n",
       "  'major': 'computer science',\n",
       "  'name': 'Gary'},\n",
       " {'age': 23,\n",
       "  'grades': {'calculus': 94,\n",
       "   'control systems': 95,\n",
       "   'electronics': 99,\n",
       "   'french': 88},\n",
       "  'hobbies': ['swimming', 'reading', 'drawing', 'public speaking'],\n",
       "  'major': 'electrical engineering',\n",
       "  'minor': 'management',\n",
       "  'name': 'Jill'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This data structure lends itself to being written to a json file. This can be done like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('test_json.json', 'w') as f:\n",
    "    json.dump(student_list, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this example we used the optional `indent` parameter to make it print the content in an easy to read format. We can leave that out to be more compact and appear on one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"major\": \"computer science\", \r\n",
      "    \"name\": \"Gary\", \r\n",
      "    \"age\": 22, \r\n",
      "    \"grades\": {\r\n",
      "      \"linear algebra\": 97, \r\n",
      "      \"cpu design\": 94, \r\n",
      "      \"english\": 82\r\n",
      "    }, \r\n",
      "    \"hobbies\": [\r\n",
      "      \"running\", \r\n",
      "      \"climbing trees\", \r\n",
      "      \"eating ice cream\"\r\n",
      "    ], \r\n",
      "    \"employment\": [\r\n",
      "      \"librarian\", \r\n",
      "      \"research assistant\"\r\n",
      "    ]\r\n",
      "  }, \r\n",
      "  {\r\n",
      "    \"major\": \"electrical engineering\", \r\n",
      "    \"name\": \"Jill\", \r\n",
      "    \"age\": 23, \r\n",
      "    \"grades\": {\r\n",
      "      \"calculus\": 94, \r\n",
      "      \"electronics\": 99, \r\n",
      "      \"control systems\": 95, \r\n",
      "      \"french\": 88\r\n",
      "    }, \r\n",
      "    \"hobbies\": [\r\n",
      "      \"swimming\", \r\n",
      "      \"reading\", \r\n",
      "      \"drawing\", \r\n",
      "      \"public speaking\"\r\n",
      "    ], \r\n",
      "    \"minor\": \"management\"\r\n",
      "  }\r\n",
      "]"
     ]
    }
   ],
   "source": [
    "!cat test_json.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can read the file back by parsing the file contents with the `load` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'age': 22,\n",
       "  u'employment': [u'librarian', u'research assistant'],\n",
       "  u'grades': {u'cpu design': 94, u'english': 82, u'linear algebra': 97},\n",
       "  u'hobbies': [u'running', u'climbing trees', u'eating ice cream'],\n",
       "  u'major': u'computer science',\n",
       "  u'name': u'Gary'},\n",
       " {u'age': 23,\n",
       "  u'grades': {u'calculus': 94,\n",
       "   u'control systems': 95,\n",
       "   u'electronics': 99,\n",
       "   u'french': 88},\n",
       "  u'hobbies': [u'swimming', u'reading', u'drawing', u'public speaking'],\n",
       "  u'major': u'electrical engineering',\n",
       "  u'minor': u'management',\n",
       "  u'name': u'Jill'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('test_json.json', 'r') as f:\n",
    "    student_list2 = json.load(f)\n",
    "    \n",
    "student_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You should see a few differences. One, the strings (`str`) were converted to unicode (`unicode`). Unicode refers to how the text is encoded in bytes. The difference isn't important here.\n",
    "\n",
    "You'll also know that the first student had an `employment` key that was previously mapped to a `tuple`, but is now\n",
    "mapped to a list. The JSON data format has no concept of a `tuple` so when a tuple is serialized, it is recreated as a list.\n",
    "\n",
    "The object types are all `list`s and `dict`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'>\n",
      "<type 'list'>\n",
      "<type 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print type(student_list2[0])\n",
    "print type(student_list2[0]['employment'])\n",
    "print type(student_list2[0]['grades'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Interesting side note: The IPython notebook you are looking at right now is a JSON file. The data each cell and its output can easily be represented in JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      " \"cells\": [\r\n",
      "  {\r\n",
      "   \"cell_type\": \"code\",\r\n",
      "   \"execution_count\": null,\r\n",
      "   \"metadata\": {\r\n",
      "    \"collapsed\": true\r\n",
      "   },\r\n",
      "   \"outputs\": [],\r\n",
      "   \"source\": [\r\n",
      "    \"%matplotlib inline\\n\",\r\n",
      "    \"import matplotlib\\n\",\r\n",
      "    \"import seaborn as sns\\n\",\r\n",
      "    \"matplotlib.rcParams['savefig.dpi'] = 144\"\r\n",
      "   ]\r\n",
      "  },\r\n",
      "  {\r\n",
      "   \"cell_type\": \"code\",\r\n",
      "   \"execution_count\": null,\r\n",
      "   \"metadata\": {\r\n",
      "    \"collapsed\": true\r\n",
      "   },\r\n",
      "   \"outputs\": [],\r\n",
      "   \"source\": [\r\n",
      "    \"import numpy as np\\n\",\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 25 IW_Data_Formats.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### JSON and APIs\n",
    "\n",
    "The JSON data format is commonly used for communicating with modern APIs.\n",
    "\n",
    "Let's look at a simple example of consuming a JSON API.  The example we'll look at is a *geocoder*: That is, a service for converting between addresses and normalized geographic information (e.g. latitude and longitude).  Going from addresses to normalized form is \"forward geocoding\" and going the other way is \"reverse geocoding\".\n",
    "\n",
    "We'll interact with a free (and non-authenticated) geocoder run by OpenStreetMap.  The geocoded information is available by sending a GET request to <tt>http:&#8203;//nominatim.openstreetmap.org/search?q=<i>address</i>&addressdetails=1&format=json</tt>.  The portion before the question mark (`http://nominatim.openstreetmap.org/search`) is the endpoint on the server, while the portion following, known as the *query string*, contains the data being sent to the server.  (Thus, a GET request can be repeated simply by requesting the same URL again.  In contrast, the data sent in a POST request is contained in the request body, not in the URL.)\n",
    "\n",
    "As is typical, the query string consists of several key=value pairs, separated by ampersands.  The requested address is specified with the `q` key in this case.  Some characters, like the spaces and commas, cannot be using in the URL, so they must be encoded.  To save you the pain of doing that manually, the `requests` module takes a dictionary of key-value pairs and formats the query string for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "address = \"11604 Fulham Street 20902\"\n",
    "\n",
    "response = requests.get(\"http://nominatim.openstreetmap.org/search\",\n",
    "                        params={'q': address, \n",
    "                                'addressdetails': 1, \n",
    "                                'format': 'json'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The response object that is returned records the URL that was used..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'http://nominatim.openstreetmap.org/search?q=11604+Fulham+Street+20902&addressdetails=1&format=json'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "...as well as the response that the server gave.  (200 is the HTTP response for OK.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 'OK')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code, response.reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The data returned by the server is available in the `.text` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'[{\"place_id\":\"63209438\",\"licence\":\"Data \\xa9 OpenStreetMap contributors, ODbL 1.0. http:\\\\/\\\\/www.openstreetmap.org\\\\/copyright\",\"osm_type\":\"way\",\"osm_id\":\"5975353\",\"boundingbox\":[\"39.043525\",\"39.047622\",\"-'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that the text has been properly decoded into unicode.  (The string is prefixed by `u`.)  If you need the raw bytes for some reason, they are available in the `.content` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"place_id\":\"63209438\",\"licence\":\"Data \\xc2\\xa9 OpenStreetMap contributors, ODbL 1.0. http:\\\\/\\\\/www.openstreetmap.org\\\\/copyright\",\"osm_type\":\"way\",\"osm_id\":\"5975353\",\"boundingbox\":[\"39.043525\",\"39.047622\",\"'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We could interpret this text as JSON with `json.loads`, but `requests` provides a convenience method `.json()` on the response object that does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'address': {u'country': u'United States of America',\n",
       "   u'country_code': u'us',\n",
       "   u'county': u'Montgomery County',\n",
       "   u'locality': u'Kemp Mill',\n",
       "   u'neighbourhood': u'Northwood Forest',\n",
       "   u'postcode': u'20902',\n",
       "   u'road': u'Fulham Street',\n",
       "   u'state': u'Maryland'},\n",
       "  u'boundingbox': [u'39.043525', u'39.047622', u'-77.027832', u'-77.024993'],\n",
       "  u'class': u'highway',\n",
       "  u'display_name': u'Fulham Street, Northwood Forest, Kemp Mill, Montgomery County, Maryland, 20902, United States of America',\n",
       "  u'importance': 0.41,\n",
       "  u'lat': u'39.044986',\n",
       "  u'licence': u'Data \\xa9 OpenStreetMap contributors, ODbL 1.0. http://www.openstreetmap.org/copyright',\n",
       "  u'lon': u'-77.027793',\n",
       "  u'osm_id': u'5975353',\n",
       "  u'osm_type': u'way',\n",
       "  u'place_id': u'63209438',\n",
       "  u'type': u'residential'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'39.043525', u'39.047622', u'-77.027832', u'-77.024993']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()[0]['boundingbox']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## CSV Files\n",
    "\n",
    "The Python standard library includes a library for reading and writing csv files. It doesn't have some of the advanced csv features that the Pandas library comes with, but it is still a respectable library in its own right.\n",
    "\n",
    "Here is an example of writing some sample data to a file using this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv.writer\n",
    "\n",
    "data = []\n",
    "data.append(['this', 'is', 'a', 'test'])\n",
    "data.append(['what', 'will an', 'extra, comma', 'do?'])\n",
    "data.append(['some', 'numbers', 42, 3.14])\n",
    "\n",
    "with open('csv_test.csv', 'w') as csvfile:\n",
    "    test_writer = csv.writer(csvfile)\n",
    "    for row in data:\n",
    "        test_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can observe that the file was written to disk, as expected. Take note of how it handled the extra comma in one of the strings. Without that, it would be confused by the comma and think that there is an extra column in that row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this,is,a,test\r",
      "\r\n",
      "what,will an,\"extra, comma\",do?\r",
      "\r\n",
      "some,numbers,42,3.14\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat csv_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'is', 'a', 'test'],\n",
       " ['what', 'will an', 'extra, comma', 'do?'],\n",
       " ['some', 'numbers', '42', '3.14']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = []\n",
    "\n",
    "with open('csv_test.csv', 'r') as csvfile:\n",
    "    test_reader = csv.reader(csvfile)\n",
    "    for row in test_reader:\n",
    "        data2.append(row)\n",
    "        \n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You'll notice that `data2` is not quite the same as `data`...can you see the difference?\n",
    "\n",
    "The numbers `42` and `3.14` are now strings. Unlike pickle files, the types of the data are not preserved.\n",
    "\n",
    "Later we will learn about Pandas and its read_csv function. This library has many advanced features for inferring column types as integers or floats. It can also automatically parse date columns. This can save you time when working with complex CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## XML Files\n",
    "\n",
    "XML files are less popular these days than JSON files. As a data format they have a reputation for being larger and more cumbersome. There is some truth to this, but it's also true that XML can be more than a data format, whereas JSON files are only a data format. We won't get into these differences here, as we are only concerned with data right now.\n",
    "\n",
    "To read and write xml files, we will use the non-standard library `lxml`. We will start by creating XML elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<student_list>\n",
      "  <student>\n",
      "    <name type=\"first name\">Gary</name>\n",
      "    <major>computer science</major>\n",
      "    <hobbies>\n",
      "      <hobby>running</hobby>\n",
      "      <hobby>climbing trees</hobby>\n",
      "      <hobby>eating ice cream</hobby>\n",
      "    </hobbies>\n",
      "  </student>\n",
      "</student_list>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "student_list = etree.Element(\"student_list\")\n",
    "\n",
    "student1 = etree.SubElement(student_list, \"student\")\n",
    "name1 = etree.SubElement(student1, \"name\")\n",
    "name1.text = \"Gary\"\n",
    "name1.set('type', 'first name')\n",
    "\n",
    "major1 = etree.SubElement(student1, \"major\")\n",
    "major1.text = \"computer science\"\n",
    "\n",
    "hobbies1 = etree.SubElement(student1, \"hobbies\")\n",
    "hobby1 = etree.SubElement(hobbies1, \"hobby\")\n",
    "hobby1.text = 'running'\n",
    "hobby2 = etree.SubElement(hobbies1, \"hobby\")\n",
    "hobby2.text = 'climbing trees'\n",
    "hobby3 = etree.SubElement(hobbies1, \"hobby\")\n",
    "hobby3.text = 'eating ice cream'\n",
    "\n",
    "student_list_xml = etree.tostring(student_list, pretty_print=True)\n",
    "\n",
    "print student_list_xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As you can see, this is tedious to prepare XML. If you are working with data in Python it is much simpler to use JSON.\n",
    "\n",
    "Nevertheless, it can be written to a text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('test_xml.xml', 'w') as f:\n",
    "    f.write(student_list_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<student_list>\r\n",
      "  <student>\r\n",
      "    <name type=\"first name\">Gary</name>\r\n",
      "    <major>computer science</major>\r\n",
      "    <hobbies>\r\n",
      "      <hobby>running</hobby>\r\n",
      "      <hobby>climbing trees</hobby>\r\n",
      "      <hobby>eating ice cream</hobby>\r\n",
      "    </hobbies>\r\n",
      "  </student>\r\n",
      "</student_list>\r\n"
     ]
    }
   ],
   "source": [
    "!cat test_xml.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "XML consists of a nested set of tags, with the tag hierarchy defined by the ordering of the open and close tags.\n",
    "\n",
    "Observe the XML tags are similar to the keys used in the previous JSON file. The text between the open and close tags contain other tags or text. The tags can also have attributes, as we did above with `type=\"first name\"`.\n",
    "\n",
    "This can be retrieved and parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<student_list>\n",
      "  <student>\n",
      "    <name type=\"first name\">Gary</name>\n",
      "    <major>computer science</major>\n",
      "    <hobbies>\n",
      "      <hobby>running</hobby>\n",
      "      <hobby>climbing trees</hobby>\n",
      "      <hobby>eating ice cream</hobby>\n",
      "    </hobbies>\n",
      "  </student>\n",
      "</student_list>\n"
     ]
    }
   ],
   "source": [
    "student_list_xml2 = etree.parse('test_xml.xml')\n",
    "\n",
    "print etree.tostring(student_list_xml2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Data can also be extracted from the XML tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gary\n",
      "====\n",
      "running\n",
      "climbing trees\n",
      "eating ice cream\n"
     ]
    }
   ],
   "source": [
    "for student in student_list_xml2.findall('student'):\n",
    "    name = student.find('name').text\n",
    "    print name\n",
    "    print '=' * len(name)\n",
    "    hobbies = student.find('hobbies')\n",
    "    for hobby in hobbies.findall('hobby'):\n",
    "        print hobby.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "XML files as a data format are not as easy to use but you may need to read them at some point in your career as a Data Scientist.\n",
    "\n",
    "Also note that strict HTML can also be valid XML, and some HTML parsers (BeautifulSoup) will try to leverage this to quickly parse a web page. SVG image files are also XML, so you can use the lxml package to read and write them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercises\n",
    "\n",
    "1. Find a CSV file somewhere on the Internet that contains data that interests you. Open the file with the `csv` library we learned about.\n",
    "1. Same thing, but for a JSON file.\n",
    "1. Using OpenStreetMap, search for your own address. Extract your latitude and longitude from the returned JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exit Tickets\n",
    "\n",
    "1. Why is it important to close files after opening them?\n",
    "1. What is file compression and when would it be useful?\n",
    "2. What is a Pickle file? Are there any Python objects that cannot be pickled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Copyright &copy; 2016 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
