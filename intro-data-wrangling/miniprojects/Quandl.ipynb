{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import grader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quandl Miniproject\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Data provider [Quandl](https://www.quandl.com/) offers a vast array of free and paid databases, all accessible with the same Python API (application program interface). Quandl aggregates data from many sources, ranging from scientific to economic to government related topics. They conveniently provide the data to you in powerful Pandas DataFrames.\n",
    "\n",
    "**In this project, you will gain experience working with Python and Pandas using the data from Quandl.**\n",
    "\n",
    "At the completion of this project, you will understand how to access all of the Quandl data and how to then wrangle that data in Pandas.\n",
    "\n",
    "## Getting Data From Quandl\n",
    "\n",
    "To use Quandl you will have to create an API key. The purpose of the API key is to make it easy for Quandl to track the usage of their data (creating data for them to study!) and for them to ensure that no one user is abusing their system with too many requests.\n",
    "\n",
    "Create an API key by first creating an account on [Quandl](https://www.quandl.com/). You can log in with your Google, Github or LinkedIn accounts if you like.\n",
    "\n",
    "After creating an account, access your *Account Settings* from the *Me* dropdown in the upper right corner. Then click on the *API KEY* link on the left below *PASSWORD*. Save the API Key: you'll need that in a moment.\n",
    "\n",
    "There is [documentation](https://www.quandl.com/docs/api?python#) available for the API. You'll need to look through that to find a few pieces of information, but we will walk you through the basics right now.\n",
    "\n",
    "### Test Query\n",
    "\n",
    "Quandl provides a Python module that allows for easy access to their API.  Let's make sure we have the right version installed.  It should start with a 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import quandl\n",
    "print quandl.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, tell Quandl about the API key you created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quandl.ApiConfig.api_key = '<API KEY>'  # Fill in your value here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will access some Sunspot data. Visit Quandl's page for the [Solar Influences Data Analysis Center](https://www.quandl.com/data/SIDC/SUNSPOTS_D-Total-Sunspot-Numbers-Daily).\n",
    "\n",
    "This is daily data collected by the Royal Observatory of Belgium starting in 1818. Observe in the upper right hand corner of the page you will find a *Quandl Code*. You will need this code to access this specific dataset. Each dataset has its own code, which you can use to download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sunspots = quandl.get('SIDC/SUNSPOTS_D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string 'SIDC/SUNSPOTS_D' is a code for retrieving specific data offered by Quandl. 'SIDC' refers to the Royal Observatory database, and 'SUNSPOTS_D' is a specific dataset in that database.\n",
    "\n",
    "Let's take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sunspots.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sunspots['Daily Sunspot Number'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's how easy Quandl is! Find the Quandl code for the data you want and then call the `get` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "At the end of each of the following sections is a function that returns a list of data.  Currently, they return placeholder data.  You should alter these functions to return the correct data.  These functions are passed to the `score()` function that will submit the data to the grader and print out your grade.\n",
    "\n",
    "## Question 1: wiki_data\n",
    "We want to find the daily percentage change in the closing price for the first 100 trading days of 2016 for Tableau Software (ticker symbol DATA).  This should be returned as a list of 100 tuples of (date, percentage).\n",
    "- Format the dates as strings like \"7/04/16\" for July 4th or \"11/01/16\" for November 1st.\n",
    "  - **IMPORTANT**: look closely at the date format. The date has a leading zero but the month does not. The year is represented with two digits. Admittedly this is not a standard way of representing dates. The goal is to get you to think carefully about date formatting [directives](http://strftime.org/).\n",
    "- The returns will be percentages, not fractions. Therefore, submit a return of one-and-a-half percent as 1.5, not 0.015.\n",
    "\n",
    "Quandl provides stock prices in the \"WIKI EOD Stock Prices\" database.  Use the search feature on the Quandl website to find the code for this dataset.  Use this with `start_date='2015-12-31'` keyword argument to get only the data from 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prices = quandl.get(..., start_date='2015-12-31')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe you get should have several hundred rows and 12 columns, with a datetime index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert prices.shape[1] == 12\n",
    "print type(prices.index)\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe you get should have several hundred rows and 12 columns, with a datetime index.  The only column we need is the \"Adj. Close\" column, which is adjusted for corporate actions like dividends and splits.  Use the `.pct_change()` method on this column to get the daily fractional change and then adjust it to be a percentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "close_change = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dates are the index of the dataframe.  They can be made into a column with the `.reset_index()` method, or accessed directly with via the `.index` property of the dataframe or `close_change` series.  Once you have the dates, use the `.strftime()` method to format them as strings, with [these directives](http://strftime.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_str = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, combine these two results into a list of tuples.  There are several approaches to this, including:\n",
    "1. Make the two series into columns in the same dataframe.  Use a list comprehension over the [`.itertuples()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples) generator to produce a list of tuples.\n",
    "2. Use [`zip()`](https://docs.python.org/2/library/functions.html#zip) to join the two series into a list of tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, combine these two results into a list of tuples.  There are several approaches to this; we'll use [`zip()`](https://docs.python.org/2/library/functions.html#zip) to join the two series into a list of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiki_data_tuples = zip(date_str, close_change)\n",
    "\n",
    "print wiki_data_tuples[0]\n",
    "print len(wiki_data_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two problems with this:\n",
    "1. The first element is a NaN from the last day of 2015.\n",
    "2. There are more than 100 tuples.\n",
    "\n",
    "Select the first 100 days of 2016, and submit those to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wiki_data_tuples_all = zip(date_str, close_change)\n",
    "wiki_data_tuples = ...\n",
    "\n",
    "def wiki_data():\n",
    "    return wiki_data_tuples\n",
    "\n",
    "grader.score('quandl__wiki_data', wiki_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: state_industry_pairs\n",
    "The rest of the questions will use data provided by the US [Bureau of Labor Statistics](https://www.quandl.com/data/BLSE?keyword=). Among other things, they track monthly employment numbers by industry for each state.\n",
    "\n",
    "We are specifically interested in their *State and Area Employment, Hours, and Earnings* data, as described in their [documentation](https://www.quandl.com/data/BLSE/documentation/documentation). The documentation describes the *Code Nomenclature* for data files for all of the permutations of states and industries and seasonally/not seasonally adjusted data.\n",
    "\n",
    "Each of these datasets looks like this one:\n",
    "\n",
    "https://www.quandl.com/data/BLSE/SMS01000004300000001-All-Employees-In-Thousands-Transportation-and-Utilities-Alabama\n",
    "\n",
    "For these questions you will need to use all of these datasets in this subgroup of the BLS database. There will be about ~1118 datasets in total. To obtain all of them, you could use the information provided in the documentation and query each quandl code permutation. Another approach is to download a (zipped) database metadata file from this URL using the Linux command wget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://www.quandl.com/api/v3/databases/BLSE/codes.zip -O codes.zip -nc\n",
    "unzip -u codes.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can load all of the codes into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codes = pd.read_csv('BLSE-datasets-codes.csv', header=None,\n",
    "                    names=('Code', 'Description'))\n",
    "codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the datasets with employment information have a description that begins, \"All Employees\".  Create a new data frame that contains only those rows.  There should be 1118 in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_rows = ...\n",
    "valid_codes = codes[valid_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert valid_codes.shape[0] == 1118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to download and store the data from each of those dataset.  Let's start by downloading the data from the beginning of 2006 to the end of 2015, for a single set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code = 'BLSE/SMS54000003000000001'\n",
    "description = 'All Employees, In Thousands; Manufacturing - West Virginia'\n",
    "\n",
    "df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because you will need to combine this data with the other sets, add columns for the state, category, and a flag for whether the data are adjusted.  If `df` is a dataframe, a constant column can be added with\n",
    "```python\n",
    "df['State'] = pd.Series('West Virginia', index=df.index)\n",
    "```\n",
    "Instead of hard-coding the values, though, work them out either through the code, as [described](https://www.quandl.com/data/BLSE-BLS-Employment-Unemployment/documentation/documentation), or the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = ...\n",
    "category = ...\n",
    "adjusted = ...\n",
    "\n",
    "df['State'] = pd.Series(state, index=df.index)\n",
    "df['Category'] = pd.Series(category, index=df.index)\n",
    "df['Adjusted'] = pd.Series(adjusted, index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, combine this code into a single function, for future reuse.  It's best to have this function write the dataframe to a file.  This way, if a data retrieval fails, you can rerun just that dataset.  If you need to restart the notebook, you won't need to download all of the data again.\n",
    "\n",
    "You can use Pandas' `to_pickle()` and `from_pickle()` functions, or another mechanism.  The checkpoint library [ediblepickle](https://pypi.python.org/pypi/ediblepickle/1.1.3) could also be used to streamline the process so that the time-consuming code will only be run when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(code, description):\n",
    "    # Download data\n",
    "    # Add columns\n",
    "    # Save locally\n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "get_data(code, description).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you've tested that function for several datasets, write a loop to download all of the data sets.\n",
    "\n",
    "The speed of that loop might be faster than Quandl's limit. To slow it down you can tell Python to `sleep` for a short time to keep it under the threshold.\n",
    "```python\n",
    "import time\n",
    "time.sleep(0.1)  # sleep for 0.1 seconds (100 ms)\n",
    "```\n",
    "\n",
    "If you add that to your function above, we can load all of the data into a single dataframe with the `concat()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat(get_data(code, description) for code, description\n",
    "                   in valid_codes.itertuples(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each question will pertain to either the unadjusted or the adjusted data.  You may find it easier to have each in its own dataframe.  Remove the *Total Private* and *Total Nonfarm* data, as these statistics are aggegations, not industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_raw = ... # Unadjusted data\n",
    "df_adj = ... # Adjusted data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, use the *unadjusted data* to find the 100 largest state-industry pairs for December 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select out only the results from 12/2015\n",
    "dec15 = ...\n",
    "# Sort them by 'Value' and choose the top 100\n",
    "top100 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer should consist of 100 tuples of states, industry names, and employment numbers, like this: ((State, Industry), Employment #)\n",
    "\n",
    "The State and Industry names will be strings, the same as you see in the documentation.\n",
    "\n",
    "The Employment numbers will be the number of people employed on that date. Note the data is provided to you in thousands, so you will have to do some multiplication.\n",
    "\n",
    "We can do this with a list comprehension over `top100.itertuples()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_industry_tuples = [...\n",
    "                         for x in top100.itertuples(index=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this and the following questions, we give you a placeholder in the score function, so you can check that you understand the format of the answer.  Replace the return statement with one that returns `state_industry_tuples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def state_industry_pairs():\n",
    "    return [(('California', 'Service-Providing'), 14352600)] * 100\n",
    "\n",
    "grader.score('quandl__state_industry_pairs', state_industry_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: state_total_employed\n",
    "Using the unadjusted data, what are the total number of employed people in December 2015, by state?\n",
    "\n",
    "Your answer should consist of 53 tuples of states and employment numbers, like this: (State, Employment #)\n",
    "\n",
    "That's 50 states, plus Washington DC, Puerto Rico, and the Virgin Islands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def state_total_employed():\n",
    "    return [('Alabama', 2965000)] * 53\n",
    "\n",
    "grader.score('quandl__state_total_employed', state_total_employed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: state_industry_growth\n",
    "Using the unadjusted data, for each state, which industry saw the largest percent growth from December 2006 to December 2015?\n",
    "\n",
    "Your answer should consist of 53 tuples of states, industries, and percentages, like this: ((State, Industry), Percentage).\n",
    "\n",
    "The State and Industry names will be strings, the same as you see in the documentation.\n",
    "\n",
    "The Percentage will be a percentage, not fraction. Submit a return of 1.5% as 1.5, not 0.015.\n",
    "\n",
    "Start by getting the data from December 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec06 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compare rows in the `dec06` and `dec15` dataframes that have the same state and category.  When operations are conducted on dataframes, rows are matched by index.  Indices can have multiple levels.  Use the `.set_index()` method with a list as an argument to acheive this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val06 = ...\n",
    "val15 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can do math directly on the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "growth = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the largest for each state, we need to group the rows by state.  To do this, first we have to change the indices back to columns with `.reset_index()`, and then use `.groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "by_state = ...\n",
    "assert type(by_state) == pd.core.groupby.DataFrameGroupBy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `DataFrameGroupBy` object records with rows belong together, but hasn't done any calculations on the groups.  We can pull out a group for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alabama = by_state.get_group('Alabama')\n",
    "alabama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that takes this dataframe and returns the row with the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def largest_value(df):\n",
    "    ...\n",
    "\n",
    "assert largest_value(alabama)['Category'] == 'Transportation and Utilities'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the group-by object's `.apply()` method to apply this to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fastest_by_state = by_state.apply(largest_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, convert this dataframe to a list of tuples on the correct form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def state_industry_growth():\n",
    "    return [(('Alabama', 'Transportation and Utilities'), 4.5769764216366138)] * 53\n",
    "\n",
    "grader.score('quandl__state_industry_growth', state_industry_growth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: max_employment\n",
    "Using the unadjusted data, find the maximum employment number for each industry across the USA. That is, find the number of people employed in each industry during the month that that industry peaked in our dataset.\n",
    "\n",
    "Your answer should consist of 16 tuples of industries and employment numbers, like this: (Industry, Employment #)\n",
    "\n",
    "The Industry names will be strings, just like they are in the documentation.\n",
    "\n",
    "The Employment numbers will be the total number of people employed in any state in each industry. Note the data is provided to you in thousands, so you will have to do some multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_employment():\n",
    "    return [('Air Transportation', 367900)] * 16\n",
    "\n",
    "grader.score('quandl__max_employment', max_employment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: quarterly_nonfarm\n",
    "Using the seasonally adjusted data, what is the quarterly percent change for total non-farm employment across all states?\n",
    "\n",
    "Use the last data-point in each quarter to represent the data for the quarter.\n",
    "\n",
    "The first calculated percentage will be (should be) NaN, which you can exclude from your answer.\n",
    "\n",
    "Your answer should be 39 tuples of dates and percentages, like this: (Date, Percentage)\n",
    "\n",
    "Format the dates as strings like \"2016-07-04\" for July 4th or \"2016-11-01\" for November 1st.\n",
    "\n",
    "The Percentage will be a percentage, not fraction. Submit a return of\n",
    "1.5% as 1.5, not 0.015.\n",
    "\n",
    "Hint: Try using a DataFrame's `.resample()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quarterly_nonfarm():\n",
    "    return [('2006-06-30', 0.30836643956206888)] * 39\n",
    "\n",
    "grader.score('quandl__quarterly_nonfarm', quarterly_nonfarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: third_largest\n",
    "Using the unadjusted data, what is the 3rd largest industry as a percentage of each state's total industry employment in December 2015?\n",
    "\n",
    "Your answer should consist of 53 tuples of states, industries, and percentages, like this: ((State, Industry), Percentage).\n",
    "\n",
    "The State and Industry names will be strings, the same as you see in the documentation.\n",
    "\n",
    "The Percentage will be as percentages, not fractions. Submit a return of 1.5% as 1.5, not 0.015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def third_largest():\n",
    "    return [(('Alabama', 'Goods Producing'), 11.784148397976391)] * 53\n",
    "\n",
    "grader.score('quandl__third_largest', third_largest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2016 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
