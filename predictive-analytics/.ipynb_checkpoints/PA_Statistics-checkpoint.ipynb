{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Introduction to Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Statistics vs. Probability\n",
    "\n",
    "Probability is the study of how (abstract) random variables and distributions behave.  Statistics is the study of how to interpret data while making assumptions about the underlying distributions.  Probability is actually a very formal, precise calculation.  (Applied) statistics is a much more squishy subject that requires human judgment as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def plot_hist_dist(rvs, dist, title=None, label='', mean=None, confidence_interval=None, ax=None):\n",
    "    ax = ax if ax else plt.gca()\n",
    "    _, bins, _ = ax.hist(rvs, bins=50, alpha=.6, normed=True, label=(label + ' rvs').strip(), color='blue')\n",
    "    xmin, xmax = bins.min(), bins.max()\n",
    "    xpoints = np.arange(xmin, xmax, (xmax - xmin) / 100)\n",
    "    ax.plot(xpoints, dist.pdf(xpoints), label=(label+' pdf').strip(), color='black')\n",
    "    \n",
    "    if mean is not None:\n",
    "        ax.plot([mean, mean], plt.ylim(), label='mean', color='purple')\n",
    "\n",
    "    if confidence_interval:\n",
    "        ymid = np.sum(plt.ylim()) / 2.\n",
    "        plt.text(mean, ymid, 'CI', ha='center', va='bottom')\n",
    "        plt.annotate(\"\", xy=(confidence_interval[0], ymid), xycoords='data',\n",
    "                     xytext=(confidence_interval[1], ymid), textcoords='data',\n",
    "                     arrowprops=dict(arrowstyle=\"|-|\", lw=2, color='r'))    \n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    ax.legend()\n",
    "    \n",
    "def plot_hist_dist_discrete(rvs, dist, title=None, label='', ax=None):\n",
    "    ax = ax if ax else plt.gca()\n",
    "    uniques = np.unique(rvs)\n",
    "    mids = (uniques[1:] + uniques[:-1]) / 2.\n",
    "    bins = np.hstack([[uniques[0]-.5], mids, [uniques[-1] + .5]])\n",
    "    plt.hist(rvs, bins=bins, normed=True, label=(label + ' rvs').strip(), alpha=.6, color='blue')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    plt.plot(uniques, dist.pmf(uniques), label=(label + ' pmf').strip(), color='black')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Estimating Mean\n",
    "\n",
    "Let's say you have a collection of data $X_1, \\ldots, X_n$.  To estimate the mean, you would use the formula for the mean estimator\n",
    "\n",
    "$$ \\overline X = \\frac{1}{n} \\sum_{k=1}^n X_k. $$\n",
    "\n",
    "This is implemented by the function `np.mean()` or just the `.mean()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_empirical_dist(dist, size=100):\n",
    "    X = dist.rvs(size=size)\n",
    "    mean, var = dist.stats('mv')\n",
    "    rvs_mean = X.mean()\n",
    "\n",
    "    plt.hist(X, bins=20, normed=True)\n",
    "    ymin, ymax = plt.ylim()\n",
    "    ymid = (ymin + ymax) / 2.\n",
    "    plt.plot([mean]*2, [ymin, ymax], label='true mean')\n",
    "    plt.plot([rvs_mean]*2, [ymin, ymax], label='rvs mean')\n",
    "    plt.text(mean, ymid, 'std', ha='center', va='bottom')\n",
    "    plt.annotate(\"\", xy=(mean-np.sqrt(var), ymid), xycoords='data',\n",
    "                 xytext=(mean+np.sqrt(var), ymid), textcoords='data',\n",
    "                 arrowprops=dict(arrowstyle=\"|-|\", connectionstyle=\"arc3\", lw=2, color='k'))\n",
    "    plt.title(dist.dist.name)\n",
    "    plt.legend()\n",
    "    \n",
    "dists = (\n",
    "    sp.stats.expon(scale=1/2.),\n",
    "    sp.stats.beta(a=2., b=4.),\n",
    "    sp.stats.norm(loc=2., scale=4.),\n",
    "    sp.stats.chi2(df=4.)\n",
    ")\n",
    "\n",
    "for k, dist in enumerate(dists):\n",
    "    plt.subplot(2,2,k+1)\n",
    "    plot_empirical_dist(dist)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Estimating Variance\n",
    "\n",
    "Let's say you have a collection of data $X_1, \\ldots, X_n$.  To estimate the variance, one might think the right answer is\n",
    "\n",
    "$$ \\frac{1}{n} \\sum_{k=1}^n (X_k - \\overline X)^2 $$\n",
    "\n",
    "where $\\overline{X}$ is the mean estimator or the *empirical mean*.  This turns out to be **biased**.  That is, the answer is expected to be be smaller than the true variance.  Mathematically, if we let $\\mu$ be the true mean and $\\sigma^2$ be the true variance, then\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbb{E}\\left[ \\frac{1}{n}\\sum_{k=1}^n \\left(X_k-\\overline{X}\\right)^2 \\right]\n",
    "    &= \\mathbb{E}\\bigg[ \\frac{1}{n}\\sum_{k=1}^n \\big((X_k-\\mu)-(\\overline{X}-\\mu)\\big)^2 \\bigg] \\\\[4pt]\n",
    "    &= \\mathbb{E}\\bigg[ \\frac{1}{n}\\sum_{k=1}^n (X_k-\\mu)^2 -\n",
    "                              2(\\overline{X}-\\mu)(X_k-\\mu) +\n",
    "                              (\\overline{X}-\\mu)^2 \\bigg] \\\\[4pt]\n",
    "    &= \\mathbb{E}\\bigg[ \\frac{1}{n}\\sum_{k=1}^n (X_k-\\mu)^2 - (\\overline{X}-\\mu)^2 \\bigg] \\\\[4pt]\n",
    "    &= \\sigma^2 - \\mathbb{E}\\left[ \\left(\\overline{X}-\\mu\\right)^2 \\right] \\\\\n",
    "    &< \\sigma^2\\,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Mathematically, we can see that\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\mathbb{E}\\left[ \\left(\\overline{X}-\\mu\\right)^2 \\right]\n",
    "    &= \\mathbb{E}\\left[ \\left(\\frac{1}{n}\\sum_{k=1}^n (X_k-\\mu)\\right)^2 \\right] \\\\[4pt]\n",
    "    &= \\frac{1}{n^2} \\sum_{k=1}^n \\mathbb{E}\\left[ \\left(X_k-\\mu\\right)^2 \\right] \\\\\n",
    "    &= \\frac{\\sigma^2}{n}\n",
    "\\end{align}\\,\n",
    "$$\n",
    "Combining this with the above, we see that \n",
    "$$\n",
    "\\begin{align}\n",
    "    \\frac{1}{n-1} \\mathbb{E}\\left[ \\sum_{k=1}^n \\left(X_k-\\overline{X}\\right)^2 \\right]\n",
    "    &= \\frac{n}{n-1} \\cdot \\mathbb{E}\\left[ \\frac{1}{n} \\sum_{k=1}^n \\left(X_k-\\overline{X}\\right)^2 \\right] \\\\[4pt]\n",
    "    &= \\frac{n}{n-1} \\cdot \\sigma^2 \\cdot \\left( 1 - \\frac{1}{n} \\right) \\\\[4pt]\n",
    "    &= \\sigma^2 \\,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Therefore, the **unbiased estimator** of the variance is\n",
    "$$ \\hat\\sigma = \\frac{1}{n-1} \\sum_{k=1}^n (X_k - \\overline X)^2\\, $$\n",
    "\n",
    "Both are implemented by `np.var`.  For the former, set the optional parameter `df=0`, the default.  For the latter, set `df=1`.  Nominally, the unbiased estimator is assuming a single degree of freedom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dist = sp.stats.norm()\n",
    "X = dist.rvs(size=[40, 10000])\n",
    "_, var = dist.stats('mv')\n",
    "rvs_var, rvs_var_unbiased  = np.var(X, axis=0), np.var(X, axis=0, ddof=1)\n",
    "\n",
    "plt.hist(rvs_var, label='biased variance', bins=40, alpha=.5)\n",
    "plt.hist(rvs_var_unbiased, label='unbiased variance', bins=40, alpha=.5)\n",
    "plt.legend()\n",
    "plt.xlabel('Calculated variance')\n",
    "plt.ylabel('Count')\n",
    "plt.title(\"Distribution of biased and unbiased variances\")\n",
    "\n",
    "print \"True variance to unbiased variance\", np.abs(rvs_var_unbiased.mean() - var)\n",
    "print \"True variance to biased variance\", np.abs(rvs_var.mean() - var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Standard Error of Mean\n",
    "\n",
    "As we have seen, an estimate is noisy and (even if unbiased) is not always equal to its expected value.  The obvious question is what is the uncertainty of this.  More appropriately, what is the standard deviation of the distribution of the estimator given our sample size $n$?\n",
    "\n",
    "It turns out this is really easy.  Let's take our mean estimator $\\overline X$ for the sample $X_1, \\ldots, X_n$.  The Central Limit Theorem tells us that as $n$ increases, our estimate of $\\overline X$ starts to look like the normal distribution:\n",
    "\n",
    "$$ \\overline X \\sim N\\left(\\mu, \\frac{\\sigma^2}{n} \\right) $$\n",
    "\n",
    "Given an observation and an underlying distribution, the **z-score** measures the number of standard deviations the observation is above the mean.  For the case of the the observation $\\overline X$, we expect the z-score\n",
    "$$ z = \\frac{\\overline X - \\mu}{\\sigma / \\sqrt{n}} $$\n",
    "to be distributed as a standard normal (with mean zero and standard deviation one).\n",
    "\n",
    "**Gotchas:**\n",
    "- Standard deviation is not standard error!  Don't confuse the two.\n",
    "- What is the difference between the standard deviation and the standard error?\n",
    "\n",
    "### Student T Distribution\n",
    "In real life, we do not know $\\sigma$ so we often use $\\hat \\sigma$, the square root of the estimate for the variance $\\sigma^2$.  Because $\\hat\\sigma$ is now a function of the data, even if $\\overline X$ were a normal random variable, the distribution of the z score\n",
    "$$ z = \\frac{\\overline X - \\mu}{\\hat\\sigma / \\sqrt{n}} $$\n",
    "is no longer exactly normal but a [**student t** distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution) with degrees of freedom $\\nu = n - 1$.  The pdf is given by\n",
    "$$ p(x) = \\frac{\\Gamma(\\frac{\\nu+1}{2})} {\\sqrt{\\nu\\pi}\\,\\Gamma(\\frac{\\nu}{2})} \\left(1+\\frac{x^2}{\\nu} \\right)^{\\!-\\frac{\\nu+1}{2}} \\,$$\n",
    "\n",
    "The distribution satisfies the following **stats:**\n",
    "- The mean is $\\mathbb{E}[X] = 0$\n",
    "- The variance is $\\mbox{Var}[X] = \\frac{\\nu}{\\nu-2}$.\n",
    "\n",
    "Fortunately as $\\nu \\to \\infty$ (or $n \\to \\infty$), this approaches the standard normal distribution\n",
    "\n",
    "$$ \\overline X \\longrightarrow N\\left(\\mu, \\frac{\\sigma^2}{n} \\right)\\, $$\n",
    "\n",
    "where $\\mu$ and $\\sigma$ are the mean and the standard deviation of each of the $X_k$.  So we expect that the **standard error** - the standard deviation of this normal distribution - becomes\n",
    "$$ s = \\frac{\\sigma}{\\sqrt{n}}\\, $$\n",
    "\n",
    "(Of course, in real life, we do not know $\\sigma$ so we often use $\\hat \\sigma$, the square root of the estimate for the variance $\\sigma^2$).\n",
    "\n",
    "### Large n Assumption\n",
    "\n",
    "The assumption that the distribution of $\\overline X$ is normal is only valid in the limit of large $n$.  This is because\n",
    "1. Central Limit Theorem only ensures that $\\overline X$ becomes normal for large $n$ and\n",
    "1. The use of $s$ rather than $\\sigma$ ensures that we are approaching the student t distribution, which is only approximately normal if $n$ is large.\n",
    "\n",
    "What is the boundary for \"large\"?  Conventional wisdom puts it between 20 and 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Mean estimate of an exponential random variable\n",
    "\n",
    "N = 1000\n",
    "\n",
    "expon = sp.stats.expon(loc=-1.)\n",
    "sample_sizes = (None, 10, 100, 1000)\n",
    "mean, var = expon.stats(\"mv\")\n",
    "std = np.sqrt(var)\n",
    "\n",
    "for k, sample_size in enumerate(sample_sizes):\n",
    "    plt.subplot(2,2,k+1)\n",
    "    if sample_size:\n",
    "        rvs = expon.rvs(size=[sample_size, N]).mean(axis=0)\n",
    "        dist = sp.stats.norm(loc=0., scale=1./np.sqrt(sample_size))\n",
    "        plot_hist_dist(\n",
    "            rvs,\n",
    "            dist,\n",
    "            mean=mean,\n",
    "            confidence_interval=[mean - np.sqrt(var / sample_size), mean + np.sqrt(var / sample_size)],\n",
    "            title='mean estimate with {:d}'.format(sample_size),\n",
    "        )\n",
    "        plt.xlim([-1, 2])\n",
    "    else:\n",
    "        plot_hist_dist(expon.rvs(size=N), expon, title='exponential')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Confidence Intervals and Probabilities\n",
    "\n",
    "We define the $z$-$\\sigma$ **confidence interval** or $z$-standard-deviation **confidence interval** (where $z \\ge 0$) to be the interval\n",
    "$$ [\\overline X - zs, \\overline X + zs] \\,.$$\n",
    "\n",
    "If we assume the mean estimate is normally distributed, then we can use the statistics of the normal distribution to compute the probability that the mean estimate falls within the $z$-$\\sigma$ confidence interval.  If $n(x\\mid\\mu,\\sigma)$ is the normal pdf with mean $\\mu$ and standard deviation $\\sigma$, then the probability the mean falls within the $z$-$\\sigma$ confidence interval is\n",
    "\n",
    "$$ \\int_{\\overline X - zs}^{\\overline X + zs} n(x \\mid \\overline X, s)dx = \\int_{- z}^{z} n(x \\mid 0, 1)dx = N(z) - N(-z) $$\n",
    "where $N$ is the cumulative normal distribution.  We usually choose $z$ to be 2 (~95% confidence interval) or 3 (~99% confidence interval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Confidence intervals at various rates\n",
    "\n",
    "N = 1000\n",
    "\n",
    "norm = sp.stats.norm()\n",
    "\n",
    "zs = (1, 2, 2.5, 3)\n",
    "\n",
    "for k, z in enumerate(zs):\n",
    "    plt.subplot(2,2,k+1)\n",
    "    plot_hist_dist(norm.rvs(size=N), norm)\n",
    "    plt.plot([-z, -z], [0, norm.pdf(-z)], 'r', label='CI')\n",
    "    plt.plot([z, z], [0, norm.pdf(z)], 'r')\n",
    "    prob = norm.cdf(z) - norm.cdf(-z)\n",
    "    plt.title('{} sigma CI: {:.4f}'.format(z, prob))\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure()\n",
    "z=np.arange(0, 3., .1-1e-9)\n",
    "plt.plot(z, norm.cdf(z) - norm.cdf(-z), color='black')\n",
    "plt.xlabel('z score')\n",
    "plt.ylabel('probability captured in CI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Standard Error of Variance Estimate\n",
    "\n",
    "The mean estimator behaves normally.  How do the variance estimator (or other estimators) behave?  For normally distributed data, the variance estimator behaves as a chi-squared distribution.  The $\\chi^2$ distribution with $n$ degrees of freedom is the distribution given by the sum of $n$ independent standard normals squared:\n",
    "\n",
    "$$ \\chi^2(n) \\sim \\sum_{k=1}^n Z_k^2\\,. $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "norm = sp.stats.norm()\n",
    "sample_sizes = (None, 10, 100, 1000)\n",
    "\n",
    "for k, sample_size in enumerate(sample_sizes):\n",
    "    plt.subplot(2,2,k+1)\n",
    "    if sample_size:\n",
    "        dist = sp.stats.chi2(df=sample_size, scale=1./sample_size)\n",
    "        mean, var = dist.stats(\"mv\")        \n",
    "        plot_hist_dist(\n",
    "            sp.stats.norm().rvs(size=[sample_size, N]).var(axis=0),\n",
    "            dist,\n",
    "            mean=mean,\n",
    "            confidence_interval=[mean - np.sqrt(var), mean + np.sqrt(var)],\n",
    "            title='var est with {:d}'.format(sample_size),\n",
    "        )\n",
    "        plt.xlim([0, 3.5])\n",
    "    else:\n",
    "        plot_hist_dist(norm.rvs(size=N), norm, title='normal')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Standard Error of Proportion\n",
    "\n",
    "Sometimes using a normal distribution to approximate a variable does not quite make sense.  For instance, if we are estimating the success rate of a trial with binary outcomes, we can assume the underlying variable $X$ as Bernoulli with a probability of success $p$.  Recall $p$ is also the mean of the Bernoulli so the mean estimator $\\hat p$ is easy to compute.  From probability theory, we know that the variance is given by $\\sigma^2 = p (1-p)$.\n",
    "\n",
    "Even though we are not modeling the underlying trial $X$ as a normal distribution, we will still model the mean estimator $\\overline X$ as a normal distribution with mean $p$ and a standard error\n",
    "$$ s = \\sqrt{\\frac{p (1-p)}{n}}\\,. $$\n",
    "\n",
    "### Rule of Three\n",
    "What is the confidence interval if we have not observed a single success over $n$ Bernoulli trials?  Naively, $\\hat p$ is zero and so the confidence interval seems trivial.  Rather than doing that, we ask for what values of $p$ is the likelihood of having observed no events greater than or equal to 5%:\n",
    "$$ \\mathbb{P}[X = 0] \\ge 0.05 $$\n",
    "The left hand side is just $(1-p)^n$, and so taking logs we have\n",
    "$$ -np \\approx n \\log (1-p) \\ge \\ln(0.05) \\approx -3 $$\n",
    "and so we have\n",
    "$$ p \\lesssim \\frac{3}{n} \\,.$$\n",
    "\n",
    "That is, the 95% confidence interval is approximately $\\left[0, \\frac{3}{n}\\right]$.\n",
    "\n",
    "\n",
    "### Other Confidence Intervals\n",
    "**Question:**\n",
    "1. What would be the standard error for a counting process if we were to assume a Poisson distribution?\n",
    "1. What would be the standard error for an integer random variable if we were to assume a Geometric distribution?\n",
    "1. What would be the standard error for a memoryless wait time if we were to assume an Exponential distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "p = 0.7\n",
    "sigma = np.sqrt(p * (1-p))\n",
    "\n",
    "binom = sp.stats.binom(n=N, p=p)\n",
    "bernoulli = sp.stats.bernoulli(p=p)\n",
    "\n",
    "sample_sizes = (None, 100, 1000, 10000)\n",
    "\n",
    "for k, sample_size in enumerate(sample_sizes):\n",
    "    plt.subplot(2,2,k+1)\n",
    "    if sample_size:\n",
    "        dist = sp.stats.norm(loc=p, scale=sigma/np.sqrt(sample_size))\n",
    "        mean, var = dist.stats(\"mv\")\n",
    "        plot_hist_dist(\n",
    "            bernoulli.rvs(size=[sample_size, N]).mean(axis=0),\n",
    "            dist,\n",
    "            mean=mean,\n",
    "            confidence_interval=[mean - np.sqrt(var), mean + np.sqrt(var)],\n",
    "            title='mean est with {:d}'.format(sample_size),\n",
    "        )\n",
    "        plt.xlim([0.55, 0.85])\n",
    "    else:\n",
    "        plot_hist_dist_discrete(binom.rvs(size=N), binom, title='binomial')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Bootstrapping\n",
    "\n",
    "Estimating the error of an estimate can be difficult.  Instead of looking for closed-form solutions like the $\\chi^2$ distribution, we can just numerically compute the solutions.  In the above examples, we've computed the error of the estimate by resampling from the entire population.  Sometimes this can be costly, so instead we subsample from the data we have already collected.\n",
    "\n",
    "**Bootstrapping** involves sampling the data (with replacement), computing the estimator on the sample, and using that to infer *nonparametric* estimates of your confidence interval.  Let's suppose the statistic we want to compute on the data $X_1,\\ldots,X_N$ is $\\theta(X_1,\\ldots,X_N)$.  For example, $\\theta$ might be the mean or variance estimators we proposed above.  Next, let's call $\\hat \\theta_k$ the result of applying $\\theta$ on the $k$-th random subsample of the data $X_1,\\ldots,X_N$.  Then the variance of the estimator of $\\theta$ is given by\n",
    "\n",
    "$$ \\frac{1}{B-1} \\sum_{k=1}^B \\left( \\hat \\theta_k - \\frac{1}{B} \\sum_{j=1}^B \\hat \\theta_j\\ \\right)^2\\, $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N = 400\n",
    "bootstrap_number = 200\n",
    "\n",
    "def bootstrap_samples(rvs, estimator, bootstrap_number):\n",
    "    n = len(rvs)\n",
    "    return np.array([estimator(np.random.choice(rvs, size=n)) for _ in xrange(bootstrap_number)])\n",
    "\n",
    "dists = (\n",
    "    sp.stats.beta(a=2., b=4.),\n",
    "    sp.stats.chi2(df=10),\n",
    "    sp.stats.expon(),\n",
    "    sp.stats.gamma(a=1.99),\n",
    "    sp.stats.norm(),\n",
    "    sp.stats.uniform(),\n",
    ")\n",
    "\n",
    "for k, dist in enumerate(dists):\n",
    "    plt.subplot(3,2,k+1)\n",
    "    mean, var = dist.stats(\"mv\")\n",
    "    rvs = dist.rvs(size=N)\n",
    "    samples = bootstrap_samples(\n",
    "        rvs,\n",
    "        estimator=lambda x: np.mean(x) - rvs.mean(),\n",
    "        bootstrap_number=bootstrap_number\n",
    "    )\n",
    "    \n",
    "    norm = sp.stats.norm(loc=0., scale=np.sqrt(var / (N-1)))\n",
    "    plot_hist_dist(samples, norm, title=dist.dist.name)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "Hypothesis testing and confidence intervals (or more broadly bootstrapping) are two sides of the same coin.  The former tells you about estimators that you've sampled and what it could be.  The latter tells you about what those estimators cannot be.  More precisely, the mantra of hypothesis testing is that it's not possible to prove something, but we can show alternatives are highly unlikely.\n",
    "\n",
    "In hypothesis testing, we define a **null hypothesis** $H_0$ -- which is often the opposite of what we are looking for -- and then compute how unlikely it would be to observe that given the current data.  Here are a few examples:\n",
    "\n",
    "**Example:** Let's try to prove that the mean estimate of a population $\\overline X$ is greater than zero.  We may assume that if it were zero (the null hypothesis or $H_0$), it would be normally distribution with mean $0$ and standard deviation $\\sigma$.  We might set $s = \\frac{\\hat \\sigma}{\\sqrt{n}}$, the square root of the estimator for variance divided by the square root of the number of samples.\n",
    "\n",
    "We would then compute the **p value** or the probability of observing $\\overline X$ *or a result that is more extreme*.  A p value of less than 5% is often taken as evidence to reject the null hypothesis.  What does more extreme mean?  Here are two common definitions:\n",
    "1. **One sided test:** If we are testing whether $\\overline X$ is statistically significantly greater than $\\mu$, the p value would be given by\n",
    "$$1-N\\left(\\overline X \\mid \\mu, \\sigma^2\\right) = 1-N\\left(z \\mid 0, 1\\right)$$\n",
    "where $N(x \\mid \\mu,\\sigma^2)$ is the normal cdf with mean $\\mu$ and standard deviation $\\sigma$.  If we are testing whether $\\overline X$ is statistically significantly less than zero, the p value would be $N\\left(\\overline X \\mid \\mu, \\sigma^2\\right)$.  As usual, we will probably use $\\sigma = \\hat \\sigma$, the estimated standard deviation.\n",
    "1. **Two sided test:** We are testing whether $\\overline X$ is different (either greater or smaller) than $\\mu$ and if this is statistically significant.  The $p$ value is given by $2 \\cdot N\\left(-\\left|\\overline X\\right|  \\mid  \\mu, \\sigma^2\\right)$.\n",
    "\n",
    "### Multiple Hypothesis Testing\n",
    "\n",
    "Sometimes, instead of testing for just one hypothesis, we end up testing for multiple hypotheses.  This can be very dangerous and is generally something to be avoided.  For example, assume that we are rejecting null hypotheses at 5% p-values.  That is, we reject null hypotheses if, assuming they were true, we would expect to see data this extreme less than 5% of the time.  Then, if we test 20 independent null hypotheses, we'd expect to see sample data that falls outside of a 5% p-value at least once. Hence, we'd expect to (incorrectly) reject 1 null hypothesis even in the event that all 20 null hypotheses were true.\n",
    "\n",
    "There are corrections for this (for example, the [Bonferroni correction](https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mu_actual = .2\n",
    "mu_hypothesis = 0.\n",
    "N = 100\n",
    "\n",
    "X = sp.stats.norm(loc=mu_actual).rvs(size=N)\n",
    "norm = sp.stats.norm(loc=mu_hypothesis, scale=1. / np.sqrt(len(X)))\n",
    "bootstrap_rvs = bootstrap_samples(X, np.mean, 1000)\n",
    "def two_sided_p_value(rvs):\n",
    "    return 2 * norm.cdf(-np.abs(rvs.mean()))\n",
    "\n",
    "title = 'Hypothesis pdf vs bootstrapped means.  p-value {}'.format(two_sided_p_value(X))\n",
    "plot_hist_dist(bootstrap_rvs, norm, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hypothesis Testing Two Means\n",
    "\n",
    "A common question we may have is whether $\\overline X$, the mean of $X_1, \\ldots, X_m$ and $\\overline Y$, the mean of $Y_1, \\ldots, Y_n$ are different.  From above, we know that\n",
    "\n",
    "$$ \\overline X \\longrightarrow N\\left(\\mu_X, \\frac{\\sigma^2_X}{m} \\right) \\qquad \\overline Y \\longrightarrow N\\left(\\mu_Y, \\frac{\\sigma^2_Y}{n} \\right)\\,. $$\n",
    "\n",
    "Because we know that the sum of two normal distributions is also normal, we know that\n",
    "\n",
    "$$ \\overline X - \\overline Y \\longrightarrow N\\left(\\mu_X - \\mu_Y, \\frac{\\sigma^2_X}{m} + \\frac{\\sigma^2_Y}{n} \\right)\\,. $$\n",
    "\n",
    "We can use the above to compute a z score for the difference $\\overline X - \\overline Y$.  This tells us that we can easily hypothesize that the means are the same.\n",
    "\n",
    "**Questions:**\n",
    "1. How do we hypothesis test if $\\overline X > \\overline Y$ for a specific p value?\n",
    "1. How do the formulas change if we model the underlying variables $X$ and $Y$ as Bernoulli trials?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hypothesis Testing for Counts\n",
    "\n",
    "If we have a counting process where the Poisson assumptions are reasonable, we can apply a $\\chi^2$ test to check if the counts equal some expected means.  If we hypothesize $H_0$ that $X_1, \\ldots, X_n$ are independent Poisson random variables with expected means $\\lambda_1, \\ldots, \\lambda_n$, we can use this as a basis for hypothesis testing.  Because we know that the mean and variance of $X_k$ is $\\lambda_k$, we know that\n",
    "$$ \\frac{(X_k - \\lambda_k)^2}{\\lambda_k} $$\n",
    "would be a non-negative random variable with expected value 1.  It asymptotically approaches the square of a standard normal.  Therefore, asymptotically,\n",
    "$$ \\sum_{k=1}^n \\frac{(X_k - \\lambda_k)^2}{\\lambda_k} \\sim \\chi^2(n-1)$$\n",
    "\n",
    "Notionally, this is because we are constraining $\\sum_k X_k = \\sum_k \\lambda_k$.\n",
    "We can easily test our hypothesis $H_0$ by testing the p value and rejecting sufficiently extreme p values.\n",
    "\n",
    "**Example:** If we have counts broken up by two variables $X_{ij}$, we can apply the above to study independence.  For example, $i$ may denote whether the person is male or female, and $j$ may denote whether they are left handed, right-handed, or ambidextrous.  Then $X_{ij}$ would denote the number of people of that sex and handedness in a sample population.  We can use the $\\chi^2$ test to study whether sex and handedness are correlated.  If they are not, we expect the levels to be given by\n",
    "$$ \\lambda_{ij} = \\frac{\\hat \\lambda_{i\\cdot} \\hat \\lambda_{\\cdot j}}{\\hat  \\lambda} $$\n",
    "where\n",
    "$$ \\hat \\lambda_{i\\cdot} = \\sum_{j'} X_{i j'} \\qquad \\hat \\lambda_{\\cdot j} = \\sum_{i'} X_{i' j} \\qquad \\hat \\lambda = \\sum_{i'j'} \\lambda_{i'j'}\\,. $$\n",
    "With a little bit of math, we can see that asymptotically\n",
    "$$ \\sum_{k=1}^n \\frac{(X_k - \\lambda_k)^2}{\\lambda_k} \\sim \\chi^2((r-1)(c-1))$$\n",
    "where $r$ is the number of rows (i.e. the number of possible values of $i$; 2 for sex) and $c$ is the number of columns (i.e. the number of possible values of $j$; 3 for handedness)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Determining Distributions\n",
    "\n",
    "One common question is to have data $X_1, \\ldots, X_n$ and wonder whether it has the same distribution as a hypothetical random variable $Y$.  One way to solve this problem is to take the quantile estimate of the points $X_1, \\ldots, X_n$ and compare it to the quantile function $q_Y$ of $Y$.  That is, we plot the sorted points $\\underline X_1, \\ldots, \\underline X_n$ (which form the approximate quantile function) and the points $q_Y(1/n), \\ldots, q_Y(1)$ (or those points of the theoretical quantile function for $Y$).  In other words, we're plotting the points\n",
    "$$ (\\underline X_1, q_Y(1/n)), (\\underline X_2, q_Y(2/n))\\ldots, (\\underline X_n, q_Y(1))\\,. $$\n",
    "Remember that $q_Y(U)$ has the same distribution as $Y$ so if $X$ and $Y$ share the same distribution, then these two sets of points (which are quantile approximations) should conform to the straight line $y=x$.\n",
    "\n",
    "**Practical Usage:**\n",
    "- It turns out that `scipy` will do this for us using the function `probplot`.\n",
    "- It will also gives us the $R^2$ of this fit.  The closer to $1$, the more likely $X$ has the distribution of $Y$.\n",
    "- Finally, don't forget that large quantiles can be noisy, so don't be surprised to see a large amount of variation near the tails.\n",
    "- These are often called Q-Q plots, for quantile-quantile plots.\n",
    "- Q-Q plots are very clear but you can also apply the [Kolmogorov-Smirnov](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test) test, which essentially formulates and automates the testing of Q-Q plots.  This is handled by the function [`scipy.stats.ktest`](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.kstest.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Two-sided distributions and their plots\n",
    "\n",
    "dists = (sp.stats.norm(), sp.stats.t(df=2))\n",
    "\n",
    "for k, distx in enumerate(dists):\n",
    "    for j, disty in enumerate(dists):\n",
    "        plt.subplot(len(dists), len(dists), 1 + len(dists)*k + j)\n",
    "        rvs = distx.rvs(size=1000)\n",
    "        sp.stats.probplot(rvs, dist=disty, plot=plt)\n",
    "        plt.title('{} rvs with {} quantile'.format(distx.dist.name, disty.dist.name))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# One-sided distributions and their plots\n",
    "\n",
    "dists = (sp.stats.expon(), sp.stats.gamma(6.))\n",
    "\n",
    "for k, distx in enumerate(dists):\n",
    "    for j, disty in enumerate(dists):\n",
    "        plt.subplot(len(dists), len(dists), 1 + len(dists)*k + j)\n",
    "        rvs = distx.rvs(size=1000)\n",
    "        sp.stats.probplot(rvs, dist=disty, plot=plt)\n",
    "        plt.title('{} rvs with {} quantile'.format(distx.dist.name, disty.dist.name))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "*Copyright &copy; 2016 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
